---
title: "STAT 254 Project"
author: "Andrea Padilla"
date: "4/23/2023"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(EnsCat)
library(class)
library(caret)
library(gmodels)
library(mltest)
```

```{r}
poker_train <- read.csv("poker-hand-training-true.data")
poker_test <- read.csv("poker-hand-testing.data")

hist(poker_train[,11])

poker_cards_train = poker_train %>% select(1:10)
poker_cards_test = poker_test %>% select(1:10)
poker_hand_train = poker_train %>% select(11)
poker_hand_test = poker_test %>% select(11)

train_suits <- poker_cards_train %>% select(1, 3, 5, 7, 9)
train_values <- poker_cards_train %>% select(2, 4, 6, 8, 10)

var_names <- c("S1", "C1", "S2", "C2", "S3", "C3", "S4", "C4", "S5", "C5")
colnames(poker_cards_test) <- var_names
colnames(poker_cards_train) <- var_names

# looking at the distribution of suits and cards as well as means
boxplot(train_suits)
colMeans(train_suits)

boxplot(train_values)
colMeans(train_values)

# checking to see if the proportion of hands is roughly even between test and train data
prop.table(table(poker_test[,11]))
prop.table(table(poker_train[,11]))

# Data transformation: new data frame with 18 columns. 
# 1 column for each rank 1-13
# 4 columns for frequency of suits 1-4
# 1 column for outcome (unchanged)

rank <- c(seq(1, 13))
suit <- c("clubs", "diamonds", "hearts","spades")
```

```{r}
lineartransform <- function(df){
  dfnew <- data.frame(matrix(ncol = 18, nrow = nrow(df)))
  dfnew[is.na(dfnew)] <- 0
  colnames(dfnew) <- c(rank, suit, "hand")
  
  dfnew$hand <- df[,11]

  for (i in 1:nrow(df)){
    for (j in 1:5){
      card <- 2*j
      suit <- 2*j-1
      index <- df[i, card]
      newsuit <- df[i, suit] + 13
      dfnew[i, index] <- dfnew[i, index] + 1
      dfnew[i, newsuit] <- dfnew[i, newsuit] + 1
    }
  }
  return(dfnew)
  rm(dfnew)
}

traindata_transformed <- lineartransform(poker_train)

# test data is too large to transform, let's take a sample. 

test_sample <- slice_sample(poker_test, n = 100000)
testdata_transformed <- lineartransform(test_sample)



poker_cards_train = traindata_transformed[,1:17]
poker_cards_test = testdata_transformed[,1:17]
poker_hand_train = as.matrix(traindata_transformed[,18])
poker_hand_test = as.matrix(testdata_transformed[,18])
```


Testing models on transformed data:


```{r}
# Neural Network



pokerhand_nn <- nnet(hand ~., data = traindata_transformed, size = 1, weights = (1/table(traindata_transformed$hand)))
summary(pokerhand_nn)
nnet_predictions <- predict(pokerhand_nn, newdata = poker_cards_test)

view(nnet_predictions)
```

```{r}
inv_wts <- table(traindata_transformed$hand)/nrow(traindata_transformed)
case_wts <- matrix(data = 0, nrow = nrow(traindata_transformed), ncol = 1)

for (i in 1:nrow(traindata_transformed)){
  index <- traindata_transformed$hand[i]
  case_wts[i] <- 100*inv_wts[index+1]
}

pokerhand_nn <- nnet(hand ~., data = traindata_transformed, size = 2, weights = case_wts)
summary(pokerhand_nn)
nnet_predictions <- predict(pokerhand_nn, newdata = poker_cards_test)
table(nnet_predictions, poker_hand_test)

view(nnet_predictions)

```
Neither proportional nor inverse weighting have worked. Both predict the same class for all observations. We'll need to think of some more ways to weight classees if we want too continue with neural nets.
